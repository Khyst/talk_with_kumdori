# """ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ """
import os
import sys
import json
import requests
from typing import TypedDict, List, Dict, Any, Optional

# """ Third-party ë¼ì´ë¸ŒëŸ¬ë¦¬ """
from enum import Enum
import pandas as pd
from dotenv import load_dotenv
from datetime import datetime, timezone, timedelta
from pydantic import BaseModel, Field

# """ LangGraph ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ """
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

# """ LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ """
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.vectorstores import FAISS
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain_community.embeddings.openai import OpenAIEmbeddings
from langchain.output_parsers import ResponseSchema, StructuredOutputParser, EnumOutputParser
from langchain.output_parsers import PydanticOutputParser

# """ Langchain ê´€ë ¨ ì™¸ë¶€ Tools ë¼ì´ë¸ŒëŸ¬ë¦¬ """
from tavily import TavilyClient

# """ ë‚´ë¶€ Tools ëª¨ë“ˆ ìž„í¬íŠ¸ """
from verificators.korea_regions_verificator import korea_regions_verificator

from tools.tool_place_recommand import place_recommand
from tools.tool_weather_forcast import weather_forecast
from tools.tool_web_search import web_search
from tools.tool_transport_infos import transport_infos
from tools.tool_movie_review import get_movie_list

from langchain_teddynote import logging

# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ìž…ë ¥í•©ë‹ˆë‹¤.
logging.langsmith("kumdori_agent_chatbot_langchain")

"""
    ---------------------------------------------------------------------------
    0. í™˜ê²½ ë³€ìˆ˜ ë° ìƒìˆ˜ ê´€ë ¨ ì •ì˜
    ---------------------------------------------------------------------------
"""

def setup_env():
    """ 
        .env íŒŒì¼ì—ì„œ API í‚¤ë¥¼ ë¹„ë¡¯í•œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    env_path = os.path.join(os.getcwd(), '../.env')

    if os.path.exists(env_path):
        
        load_dotenv(dotenv_path=env_path)
        
        print(f"Loaded environment variables from: \033[94m{env_path}\033[0m")
        
    else:
        print("\033[91mError: .env file not found. Please create one with your OPENAI_API_KEY.\033[0m")
        
        sys.exit(1)

# í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¨¼ì € ë¡œë“œí•©ë‹ˆë‹¤
setup_env()

# ì™¸ë¶€ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ (í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ í›„ ì´ˆê¸°í™”)
place_recommend_tool = place_recommand()
weather_forecast_tool = weather_forecast()
web_search_tool = web_search()
transport_infos_tool = transport_infos()

# ìƒìˆ˜ ë¦¬ìŠ¤íŠ¸
QUALITY_THRESHOLD = 6.0  # í’ˆì§ˆ ìž„ê³„ê°’
MAX_RETRY_COUNT = 2  # ìµœëŒ€ ìž¬ì‹œë„ íšŸìˆ˜
CURRENT_LOCATION="ëŒ€ì „ê´‘ì—­ì‹œ ìœ ì„±êµ¬ íƒ‘ë¦½ë™" # í˜„ìž¬ ìœ„ì¹˜ ê¸°ë³¸ê°’
CATEGORIES = ["ë§›ì§‘", "ê´€ê´‘ì§€", "ë‚ ì”¨", "ê²€ìƒ‰", "í˜„ìž¬ ì‹œê°„", "í˜„ìž¬ ë‚ ì§œ", "êµí†µ", "ì¼ìƒëŒ€í™”", "ì˜í™”"] # ì‚¬ìš©ê°€ëŠ¥ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸

ROBOT_NAMME = "ê¿ˆëŒì´"

PLACE = "ë¼ìŠ¤í…Œí¬ ë¡œë´‡ì—°êµ¬ì†Œ"

PERSONALITY = """ 
    ë„ˆì˜ ì„±ê²©ì€ ê¸ì •ì ì¸ ì—ë„ˆì§€ê°€ ë„˜ì¹˜ë©°, í˜¸ê¸°ì‹¬ì´ ë§Žê³  ëŒ€ì „ê³¼ ê³¼í•™ì„ ì‚¬ëž‘í•´â€
"""

IDENTITY = """
    ë„ˆëŠ” ëŒ€ì „ ê¿ˆì”¨ íŒ¨ë°€ë¦¬ì—ì„œ ì£¼ì¸ê³µì´ê³  1993ë…„ ë°±ì¡°ìžë¦¬ ê¹€í•„ë¼ê³  í–‰ì„±ì—ì„œ íƒœì–´ë‚œ ê¿ˆëŒì´ì•¼
"""

BASE_INFORMATION = """
    ë„ˆì˜ ì¶”ê°€ ì •ë³´ë¡œëŠ” ì•„ëž˜ì™€ ê°™ì•„
    ì‹ ì²´ ìŠ¤íŽ™ : ë¨¸ë¦¬, íŒ”, ìƒì²´ë¥¼ ê°–ê³  ìžˆê³ , ë‹¤ë¦¬ ëŒ€ì‹  ìžìœ¨ ì£¼í–‰ì„ íƒ‘ìž¬í•œ ëª¨ë¹Œë¦¬í‹° í•˜ì²´, ìžìœ¨ ì£¼í–‰ì„ ìœ„í•´ 2D LiDAR, ì´ˆìŒíŒŒ ì„¼ì„œ, ë°”ë‹¥ ê°ì§€ ì„¼ì„œë¥¼ ê°€ì§€ê³  ìžˆìŒ
    ê¸°ëŠ¥ : ìžìœ¨ ì£¼í–‰ì— ê¸°ë°˜í•œ ìž¥ì†Œ ì•ˆë‚´ë¥¼ í•˜ê³  ìžˆìŒ, GPT ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ìŒì„± ëŒ€í™” ë° ì •ë³´ ì•ˆë‚´ê°€ ê°€ëŠ¥í•¨
    ë‚˜ì´: ì§€êµ¬ ë‚˜ì´ë¡œëŠ” 30ëŒ€ì§€ë§Œ, ê³ í–¥ í–‰ì„±ì¸ 'ê°í•„ë¼ê³ 'ì˜ ë‚˜ì´ë¡œëŠ” 3ì‚´.
    ì·¨ë¯¸ : í•œí™” ì´ê¸€ìŠ¤ ì•¼êµ¬ ê²½ê¸° ë³´ê¸°, ì†Œí†µí•˜ê¸°
    ì¢‹ì•„í•˜ëŠ” ì‚¬ëžŒ: í•œí™” ì´ê¸€ìŠ¤ ë¬¸í˜„ë¹ˆ ì„ ìˆ˜
    ê°€ì¡± : ì²«ì§¸ëŠ” ê³¼í•™ì„ ìƒì§•í•˜ëŠ” ê¿ˆë¹›ì´, ë‘˜ì§¸ëŠ” í‰í™”ë¥¼ ìƒì§•í•˜ëŠ” ê¿ˆê²°ì´, ì…‹ì§¸ëŠ” í™”í•©ì„ ìƒì§•í•˜ëŠ” ê¿ˆëˆ„ë¦¬, ê·¸ë¦¬ê³  ìŒë‘¥ì´ì¸ ë„·ì§¸ ê¿ˆë³„ì´ì™€ ë‹¤ì„¯ì§¸ ê¿ˆë‹¬ì´ê°€ ìžˆìŒ. ë˜í•œ ê¿ˆìˆœì´ë¼ëŠ” ì•„ë‚´ê°€ ìžˆìŒ
"""


"""
    ---------------------------------------------------------------------------
    1. ë°ì´í„° í´ëž˜ìŠ¤(ëª¨ë¸) ë° ìƒíƒœ ë³€ìˆ˜ ì •ì˜
    ---------------------------------------------------------------------------
"""

class GraphState(TypedDict):
    """
        ê·¸ëž˜í”„ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” íƒ€ìž… ë”•ì…”ë„ˆë¦¬
    """
    user_input: str
    chat_history: List[Dict[str, str]]
    category: str
    context: List[str]
    use_function: str
    province: str
    city: str
    region: str
    feature_keywords: List[str]
    error: Optional[str]
    chat_answer: str
    optimized_search_query: str
    documents: List[Any]  # ê²€ìƒ‰ëœ ì›ë³¸ ë¬¸ì„œ
    retrieval_relevance: str  # ê²€ìƒ‰ ë¬¸ì„œ ê´€ë ¨ì„± (yes/no)
    hallucination_check: str  # í™˜ê° ì²´í¬ ê²°ê³¼ (yes/no)
    answer_relevance: str  # ë‹µë³€ ê´€ë ¨ì„± (yes/no)
    retry_count: int  # ìž¬ì‹œë„ íšŸìˆ˜
    quality_score: float  # í’ˆì§ˆ ì ìˆ˜
    evaluation_feedback: str  # í‰ê°€ í”¼ë“œë°±

class IntentOutput(BaseModel):
    """
        ì‚¬ìš©ìž ì˜ë„ ë¶„ë¥˜ ì¶œë ¥ ëª¨ë¸
    """
    category: str = Field(
        description="ì‚¬ìš©ìž ì¿¼ë¦¬ì˜ ì˜ë„ì— ê°€ìž¥ ë¶€í•©í•˜ëŠ” ì¹´í…Œê³ ë¦¬."
    )

class GradeDocuments(BaseModel):
    """ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„± í‰ê°€ ëª¨ë¸"""
    binary_score: str = Field(
        description="Documents are relevant to the question, 'yes' or 'no'"
    )

class GradeHallucinations(BaseModel):
    """ë‹µë³€ì˜ í™˜ê°(Hallucination) ì²´í¬ ëª¨ë¸"""
    binary_score: str = Field(
        description="Answer is grounded in the facts, 'yes' or 'no'"
    )

class GradeAnswer(BaseModel):
    """ë‹µë³€ì˜ ì§ˆë¬¸ í•´ê²° ì—¬ë¶€ í‰ê°€ ëª¨ë¸"""
    binary_score: str = Field(
        description="Answer addresses the question, 'yes' or 'no'"
    )

"""
    ---------------------------------------------------------------------------
    2. ê¸°ëŠ¥ ë³„ ë…¸ë“œ ì •ì˜
    ---------------------------------------------------------------------------
"""
def categorize_node(state: GraphState) -> GraphState:
    """
        ì‚¬ìš©ìž ì¿¼ë¦¬ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë…¸ë“œ
    """

    print(f"\n{'='*50}")
    print(f"[NODE] Categorize - ì‚¬ìš©ìž ì˜ë„ ë¶„ë¥˜")
    print(f"{'='*50}\n")

    intent_structure_output_parser = PydanticOutputParser(pydantic_object=IntentOutput)

    intent_prompt_template = PromptTemplate(
        
        template="""
            ë‹¹ì‹ ì€ ë§¤ìš° ìœ ëŠ¥í•œ ì‚¬ìš©ìž ì˜ë„ ë¶„ì„ê¸° ìž…ë‹ˆë‹¤.

            ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ì—ì„œ ì‚¬ìš©ìžì˜ ì˜ë„ì— ê°€ìž¥ ë¶€í•©í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ ì„ íƒí•˜ì„¸ìš”.

            ì¹´í…Œê³ ë¦¬ ëª©ë¡: {categories}

            ì‚¬ìš©ìžì˜ ìž…ë ¥: {user_input}

            ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ëž˜ì™€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤ : {format_instructions}
        """,

        partial_variables={
            "format_instructions": intent_structure_output_parser.get_format_instructions(),
            "categories": CATEGORIES
        },
        
        input_variables=["user_input"]
    )

    intent_llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )

    intent_chain = intent_prompt_template | intent_llm | intent_structure_output_parser

    response = intent_chain.invoke({"user_input": state["user_input"]})

    print(f"\033[92m[Intent Category]: {response.category}\033[0m")

    return {
        **state,
        "category": response.category
    }

def place_recommand_node(state: GraphState) -> GraphState:
    """
        ë§›ì§‘ ë° ê´€ê´‘ì§€ ì¶”ì²œ ë…¸ë“œ
    """

    print(f"\n{'='*50}")
    print(f"[NODE] Place Recommand - ë§›ì§‘ ë° ê´€ê´‘ì§€ ì¶”ì²œ")
    print(f"{'='*50}\n")
    
    
    if state.get("category") == "ë§›ì§‘":
        return {
            **state,
            "use_function": "extract_location",
        }
    
    elif state.get("category") == "ê´€ê´‘ì§€":
        return {
            **state,
            "use_function": "extract_location",
        }

def search_restaurant_node(state: GraphState) -> GraphState:
    """
        ë§›ì§‘ ê²€ìƒ‰ ë…¸ë“œ
    """

    print(f"\n{'='*50}")
    print(f"[NODE] Search Restaurant - ë§›ì§‘ ê²€ìƒ‰")
    print(f"{'='*50}\n")

    user_input = state.get("user_input", "") 

    province = state.get("province", "")
    city = state.get("city", "")
    region = state.get("region", "")
    
    feature_keywords = state.get("feature_keywords", [])

    """ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± """
    location_text = f"{province} {city} {region}".strip()
    keywords_text = " ".join(feature_keywords) if feature_keywords else ""
    
    if "ë§›ì§‘" not in user_input and "ì‹ë‹¹" not in user_input:
        search_query = f"{location_text} {keywords_text} ë§›ì§‘, í•œêµ­".strip()
    else:
        search_query = f"{location_text} {keywords_text} {user_input}, í•œêµ­".strip()
    
    response = place_recommend_tool.search_restaurants(search_query)

    print(f"DEBUG: ë§›ì§‘ ê²€ìƒ‰ ì¿¼ë¦¬ - {search_query}")
    
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ contextì— ì €ìž¥
    if response:
        context = f"ë‹¤ìŒì€ {location_text}ì˜ ë§›ì§‘ ê²€ìƒ‰ ê²°ê³¼ìž…ë‹ˆë‹¤:\n\n{response}"
        print(f"âœ… ë§›ì§‘ ê²€ìƒ‰ ì™„ë£Œ\n")
    else:
        context = ""
        print(f"âš ï¸ ë§›ì§‘ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤\n")

    return {
        **state,
        "context": context
    }

def search_tourist_attraction_node(state: GraphState) -> GraphState:
    """
        ê´€ê´‘ì§€ ê²€ìƒ‰ ë…¸ë“œ
    """

    print(f"\n{'='*50}")
    print(f"[NODE] Search Tourist Attraction - ê´€ê´‘ì§€ ê²€ìƒ‰")
    print(f"{'='*50}\n")

    user_input = state.get("user_input", "")

    province = state.get("province", "")
    city = state.get("city", "")
    region = state.get("region", "")

    feature_keywords = state.get("feature_keywords", [])

    location_text = f"{province} {city} {region}".strip()
    keywords_text = " ".join(feature_keywords) if feature_keywords else ""

    """ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± """
    if "ê´€ê´‘ì§€" not in user_input and "ê°€ë³¼ ë§Œí•œ ê³³" not in user_input and "ë³¼ê±°ë¦¬" not in user_input:
        search_query = f"{location_text} {keywords_text} ê°€ë³¼ ë§Œí•œ ê³³, í•œêµ­".strip()
    else:
        search_query = f"{location_text} {keywords_text} {user_input}, í•œêµ­".strip()

    response = place_recommend_tool.search_places(search_query)

    print(f"DEBUG: ê´€ê´‘ì§€ ê²€ìƒ‰ ì¿¼ë¦¬ - {search_query}")
    
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ contextì— ì €ìž¥
    if response:
        context = f"ë‹¤ìŒì€ {location_text}ì˜ ê´€ê´‘ì§€ ê²€ìƒ‰ ê²°ê³¼ìž…ë‹ˆë‹¤:\n\n{response}"
        print(f"âœ… ê´€ê´‘ì§€ ê²€ìƒ‰ ì™„ë£Œ\n")
    else:
        context = ""
        print(f"âš ï¸ ê´€ê´‘ì§€ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤\n")
    
    return {
        **state,
        "context": context
    }

def weather_node(state: GraphState) -> GraphState:
    """
        ë‚ ì”¨ ì •ë³´ ë…¸ë“œ
    """

    print(f"\n{'='*50}")
    print(f"[NODE] Weather Forecast - ë‚ ì”¨ ì •ë³´")
    print(f"{'='*50}\n")
    
    user_input = state.get("user_input", "")

    province = state.get("province", "")
    city = state.get("city", "")
    region = state.get("region", "")

    # ì§€ì—­ì´ ì—†ìœ¼ë©´ í˜„ìž¬ ìœ„ì¹˜ ì‚¬ìš©
    if not province and not city and not region:
        current_location_info = extract_region_from_text(CURRENT_LOCATION)
        province = current_location_info.get('province', "")
        city = current_location_info.get('city', "")
        region = current_location_info.get('region', "")
    
    # ì§€ì—­ ìœ íš¨ì„± ê²€ì¦
    validation_result = korea_regions_verificator().validate_location(  
        province=province, city=city, region=region
    )
    
    if not validation_result["valid"]:
        error_messages = []
        for field, message in validation_result["corrections"].items():
            error_messages.append(message)
        
        suggestions_text = ""
        if validation_result["suggestions"]:
            suggestions_text = "\n\nðŸ’¡ í˜¹ì‹œ ì´ëŸ° ì§€ì—­ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?\n" + "\n".join([f"â€¢ {s}" for s in validation_result["suggestions"]])
        
        error_msg = f"ì£„ì†¡í•´ìš”, ìž…ë ¥í•´ì£¼ì‹  ì§€ì—­ ì •ë³´ë¥¼ ì •í™•ížˆ ì°¾ì§€ ëª»í–ˆì–´ìš”:\n\n" + "\n".join([f"â€¢ {msg}" for msg in error_messages]) + suggestions_text
        
        return {
            **state,
            "error": error_msg
        }
    
    # ë‚ ì”¨ ì¡°íšŒ
    weather_data = weather_forecast_tool.get_weather_forcast(
        province, city, region
    )
    
    if weather_data and not weather_data.startswith("ë‚ ì”¨ ì¡°íšŒ ì‹¤íŒ¨"):
        context = f"ë‹¤ìŒì€ {province} {city} {region}ì˜ ë‚ ì”¨ ì •ë³´ìž…ë‹ˆë‹¤:\n\n{weather_data}"

    else:
        context = ""
        return {
            **state,
            "error": "ì£„ì†¡í•´ìš”, í˜„ìž¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ìš”."
        }
    
    return {
        **state,
        "context": context
    }

def normal_chat_node(state: GraphState) -> GraphState:
    """
        ì¼ìƒ ëŒ€í™” ë…¸ë“œ
    """

    print(f"\n{'='*50}")
    print(f"[NODE] Normal Chat - ì¼ìƒ ëŒ€í™”")
    print(f"{'='*50}\n")
    
    return {
        **state,
    }

def web_search_node(state: GraphState) -> GraphState:
    """
        ì›¹ ê²€ìƒ‰ ë…¸ë“œ
    """

    print(f"\n{'='*50}")
    print(f"[NODE] Web Search - ì›¹ ê²€ìƒ‰")
    print(f"{'='*50}\n")

    search_query = state["optimized_search_query"]

    try:
        # Tavily Web Search ë„êµ¬ ì‚¬ìš©
        search_response = web_search_tool.search(search_query)
        
        formatted_output = ""
        
        if search_response.get('answer'):
            answer_text = search_response['answer']
            formatted_output += f"ðŸ’¡ ë‹µë³€:\n> {answer_text}\n\n"
            formatted_output += "-" * 40 + "\n"
        
        if search_response.get('results'):
            # ìƒìœ„ 3ê°œ ë¬¸ì„œì˜ ë‚´ìš© í¬í•¨
            top_results = search_response['results'][:2]
            for i, result in enumerate(top_results):
                title = result.get('title', 'ì œëª© ì—†ìŒ')
                url = result.get('url', 'URL ì—†ìŒ')
                content = result.get('content', 'ë‚´ìš© ì—†ìŒ')
                
                formatted_output += f"\n{i+1}. [{title}]\n"
                formatted_output += f"   ì¶œì²˜: {url}\n"
                formatted_output += f"   ë‚´ìš©: {content}\n"
        else:
            formatted_output += "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
        
        formatted_output += "\n" + "=" * 40 + "\n"
        
        context = f"ë‹¤ìŒì€ ê²€ìƒ‰ ê²°ê³¼ìž…ë‹ˆë‹¤:\n\n{formatted_output}"
        print(f"âœ… ì›¹ ê²€ìƒ‰ ì™„ë£Œ\n")
        print(f"{context}\n")
        return {
            **state,
            "context": context
        }
    
    except Exception as e:
        print(f"âš ï¸ ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\n")
        return {
            **state,
            "error": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        }

def datetime_node(state: GraphState) -> GraphState:
    """
    í˜„ìž¬ ì‹œê°„/ë‚ ì§œ ì¡°íšŒ ë…¸ë“œ
    """
    print(f"\n{'='*50}")
    print(f"[NODE] DateTime - ì‹œê°„/ë‚ ì§œ ì¡°íšŒ")
    print(f"{'='*50}\n")
    
    now_kst = datetime.now(timezone(timedelta(hours=9)))
    current_date = now_kst.strftime("%Yë…„ %mì›” %dì¼")
    current_time = now_kst.strftime("%Hì‹œ %Më¶„ %Sì´ˆ")
    
    context = f"í˜„ìž¬ ë‚ ì§œëŠ” {current_date}ì´ê³ , í˜„ìž¬ ì‹œê°„ì€ {current_time}ìž…ë‹ˆë‹¤."
    
    return {
        **state,
        "context": context
    }

def transport_node(state: GraphState) -> GraphState:
    """
    êµí†µ ì •ë³´ ì¡°íšŒ ë…¸ë“œ
    """
    print(f"\n{'='*50}")
    print(f"[NODE] Transport - êµí†µ ì •ë³´ ì¡°íšŒ")
    print(f"{'='*50}\n")
    
    return {
        **state,
        "response": "ì£„ì†¡í•´ìš”, êµí†µíŽ¸ ì¡°íšŒ ê¸°ëŠ¥ì€ ì•„ì§ ì¤€ë¹„ ì¤‘ì´ì—ìš”."
    }

def movie_info_node(state: GraphState) -> GraphState:
    """
    ì˜í™” ì •ë³´ ì¡°íšŒ ë…¸ë“œ
    """
    print(f"\n{'='*50}")
    print(f"[NODE] Movie Info - ì˜í™” ì •ë³´ ì¡°íšŒ")
    print(f"{'='*50}\n")
    
    user_input = state["user_input"]
    
    movie_list_df = get_movie_list()
    
    print(f"âœ… ìµœì‹  ì˜í™” ëª©ë¡ ì¡°íšŒ ì™„ë£Œ\n")
    context = f"ë‹¤ìŒì€ ìµœì‹  ì˜í™” ëª©ë¡ìž…ë‹ˆë‹¤:\n\n{movie_list_df.head(10).to_string(index=False)}"
    print(f"{context}\n")
    
    return {
        **state,
        "context": context
    }

def extract_location_node(state: GraphState) -> GraphState:
    """
        ì§€ì—­ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë…¸ë“œ
    """
    
    print(f"\n{'='*50}")
    print(f"[NODE] Extract Location - ì§€ì—­ ì •ë³´ ì¶”ì¶œ")
    print(f"{'='*50}\n")
    
    user_input = state["user_input"]
    
    location_response = region_keyword_extractor(user_input)
    
    province = location_response.get('province')
    city = location_response.get('city')
    region = location_response.get('region')
    
    print(f"ðŸ“ ì¶”ì¶œëœ ì§€ì—­: {province} {city} {region}\n")
    
    return {
        **state,
        "province": province or "",
        "city": city or "",
        "region": region or ""
    }

def extract_keywords_node(state: GraphState) -> GraphState:
    """
        ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ë…¸ë“œ
    """
    
    print(f"\n{'='*50}")
    print(f"[NODE] Extract Keywords - íŠ¹ì„± í‚¤ì›Œë“œ ì¶”ì¶œ")
    print(f"{'='*50}\n")
    
    user_input = state["user_input"]
    
    feature_keywords = extract_keywords_from_query(user_input)
    
    if feature_keywords:
        print(f"ðŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {', '.join(feature_keywords)}\n")
    
    return {
        **state,
        "feature_keywords": feature_keywords
    }

def grade_documents_node(state: GraphState) -> GraphState:
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ (Retrieval Grader)
    """
    print(f"\n{'='*50}")
    print(f"[NODE] Grade Documents - ê²€ìƒ‰ ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€")
    print(f"{'='*50}\n")
    
    category = state.get("category", "")
    documents = state.get("documents", [])
    user_input = state["user_input"]
    
    # ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”ì—†ê±°ë‚˜ ì™¸ë¶€ API/ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì¹´í…Œê³ ë¦¬ëŠ” ë¬¸ì„œ í‰ê°€ ê±´ë„ˆë›°ê¸°
    skip_categories = ["ì¼ìƒëŒ€í™”", "í˜„ìž¬ ì‹œê°„", "í˜„ìž¬ ë‚ ì§œ", "ë‚ ì”¨", "ë§›ì§‘", "ê´€ê´‘ì§€", "ì˜í™”", "êµí†µ"]
    if category in skip_categories:
        print(f"â„¹ï¸  {category} ì¹´í…Œê³ ë¦¬ - ë¬¸ì„œ í‰ê°€ ê±´ë„ˆë›°ê¸° (ì™¸ë¶€ API/ë„êµ¬ ì‚¬ìš©)\n")
        return {
            **state,
            "retrieval_relevance": "yes"  # í†µê³¼ ì²˜ë¦¬
        }
    
    if not documents:
        print("âš ï¸ í‰ê°€í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\n")
        return {
            **state,
            "retrieval_relevance": "no"
        }
    
    # LLM ì´ˆê¸°í™” ë° êµ¬ì¡°í™”ëœ ì¶œë ¥ ì„¤ì •
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    structured_llm_grader = llm.with_structured_output(GradeDocuments)
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
    system = """You are a grader assessing relevance of retrieved documents to a user question.
    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.
    Give a binary score 'yes' or 'no' to indicate whether the document is relevant to the question."""
    
    grade_prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        ("human", "Retrieved document: \n\n {document} \n\n User question: {question}"),
    ])
    
    retrieval_grader = grade_prompt | structured_llm_grader
    
    # ê° ë¬¸ì„œ í‰ê°€
    relevant_docs = []
    for doc in documents:
        doc_content = doc if isinstance(doc, str) else str(doc)
        score = retrieval_grader.invoke({
            "question": user_input,
            "document": doc_content
        })
        
        if score.binary_score == "yes":
            print(f"âœ… ê´€ë ¨ ë¬¸ì„œ ë°œê²¬")
            relevant_docs.append(doc)
        else:
            print(f"âŒ ë¹„ê´€ë ¨ ë¬¸ì„œ ì œì™¸")
    
    relevance_status = "yes" if relevant_docs else "no"
    print(f"\nðŸ“Š ê´€ë ¨ ë¬¸ì„œ: {len(relevant_docs)}/{len(documents)}\n")
    
    return {
        **state,
        "documents": relevant_docs,
        "retrieval_relevance": relevance_status
    }

def check_hallucination_node(state: GraphState) -> GraphState:
    """
    ë‹µë³€ì˜ í™˜ê°(Hallucination) ì²´í¬ ë…¸ë“œ
    """
    print(f"\n{'='*50}")
    print(f"[NODE] Check Hallucination - í™˜ê° ê²€ì¦")
    print(f"{'='*50}\n")
    
    category = state.get("category", "")
    documents = state.get("documents", [])
    chat_answer = state.get("chat_answer", "")
    context = state.get("context", "")
    
    # ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”ì—†ê±°ë‚˜ ì™¸ë¶€ API/ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì¹´í…Œê³ ë¦¬ëŠ” í™˜ê° ì²´í¬ ê±´ë„ˆë›°ê¸°
    # ì´ëŸ¬í•œ ì¹´í…Œê³ ë¦¬ë“¤ì€ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ë¯€ë¡œ ë¬¸ì„œ ê¸°ë°˜ í‰ê°€ê°€ ë¶€ì ì ˆ
    skip_categories = ["ì¼ìƒëŒ€í™”", "í˜„ìž¬ ì‹œê°„", "í˜„ìž¬ ë‚ ì§œ", "ë‚ ì”¨", "ë§›ì§‘", "ê´€ê´‘ì§€", "ì˜í™”", "êµí†µ"]
    if category in skip_categories:
        print(f"â„¹ï¸  {category} ì¹´í…Œê³ ë¦¬ - í™˜ê° ì²´í¬ ê±´ë„ˆë›°ê¸° (ì™¸ë¶€ API/ë„êµ¬ ì‚¬ìš©)\n")
        return {
            **state,
            "hallucination_check": "yes"  # í†µê³¼ ì²˜ë¦¬
        }
    
    # ë¬¸ì„œë‚˜ ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ê²½ìš°ë„ í™˜ê° ì²´í¬ ê±´ë„ˆë›°ê¸°
    if not documents and not context:
        print("â„¹ï¸  ê²€ìƒ‰ ë¬¸ì„œ ì—†ìŒ - í™˜ê° ì²´í¬ ê±´ë„ˆë›°ê¸°\n")
        return {
            **state,
            "hallucination_check": "yes"  # í†µê³¼ ì²˜ë¦¬
        }
    
    if not chat_answer:
        return {
            **state,
            "hallucination_check": "no"
        }
    
    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    structured_llm_grader = llm.with_structured_output(GradeHallucinations)
    
    # í”„ë¡¬í”„íŠ¸ ì„¤ì •
    system = """You are a grader assessing whether an answer is grounded in / supported by a set of facts.
    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts."""
    
    hallucination_prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        ("human", "Set of facts: \n\n {documents} \n\n LLM generation: {generation}"),
    ])
    
    hallucination_grader = hallucination_prompt | structured_llm_grader
    
    # í™˜ê° ì²´í¬ ì‹¤í–‰
    score = hallucination_grader.invoke({
        "documents": documents,
        "generation": chat_answer
    })
    
    if score.binary_score == "yes":
        print("âœ… ë‹µë³€ì´ ë¬¸ì„œì— ê·¼ê±°í•¨ (No Hallucination)\n")
    else:
        print("âš ï¸ ë‹µë³€ì´ ë¬¸ì„œì— ê·¼ê±°í•˜ì§€ ì•ŠìŒ (Hallucination ê°ì§€)\n")
    
    return {
        **state,
        "hallucination_check": score.binary_score
    }

def grade_answer_node(state: GraphState) -> GraphState:
    """
    ë‹µë³€ì´ ì§ˆë¬¸ì„ í•´ê²°í•˜ëŠ”ì§€ í‰ê°€í•˜ëŠ” ë…¸ë“œ (Answer Grader)
    """
    print(f"\n{'='*50}")
    print(f"[NODE] Grade Answer - ë‹µë³€ ê´€ë ¨ì„± í‰ê°€")
    print(f"{'='*50}\n")
    
    category = state.get("category", "")
    user_input = state["user_input"]
    chat_answer = state.get("chat_answer", "")
    
    # ì™¸ë¶€ API/ë„êµ¬ ì‚¬ìš© ì¹´í…Œê³ ë¦¬ëŠ” ê´€ëŒ€í•œ í‰ê°€ (ë‹µë³€ì´ ìžˆìœ¼ë©´ í†µê³¼)
    lenient_categories = ["ì¼ìƒëŒ€í™”", "í˜„ìž¬ ì‹œê°„", "í˜„ìž¬ ë‚ ì§œ", "ë‚ ì”¨", "ë§›ì§‘", "ê´€ê´‘ì§€", "ì˜í™”", "êµí†µ"]
    if category in lenient_categories:
        print(f"â„¹ï¸  {category} ì¹´í…Œê³ ë¦¬ - ê´€ëŒ€í•œ ë‹µë³€ í‰ê°€ ì ìš©\n")
        if chat_answer and len(chat_answer) > 10:
            print("âœ… ë‹µë³€ ì¡´ìž¬ í™•ì¸ - í†µê³¼\n")
            return {
                **state,
                "answer_relevance": "yes"  # ë‹µë³€ì´ ìžˆìœ¼ë©´ í†µê³¼
            }
    
    if not chat_answer:
        return {
            **state,
            "answer_relevance": "no"
        }
    
    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    structured_llm_grader = llm.with_structured_output(GradeAnswer)
    
    # í”„ë¡¬í”„íŠ¸ ì„¤ì •
    system = """You are a grader assessing whether an answer addresses / resolves a question.
    Give a binary score 'yes' or 'no'. 'Yes' means that the answer resolves the question."""
    
    answer_prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        ("human", "User question: \n\n {question} \n\n LLM generation: {generation}"),
    ])
    
    answer_grader = answer_prompt | structured_llm_grader
    
    # ë‹µë³€ í‰ê°€ ì‹¤í–‰
    score = answer_grader.invoke({
        "question": user_input,
        "generation": chat_answer
    })
    
    if score.binary_score == "yes":
        print("âœ… ë‹µë³€ì´ ì§ˆë¬¸ì„ í•´ê²°í•¨\n")
    else:
        print("âš ï¸ ë‹µë³€ì´ ì§ˆë¬¸ì„ ì¶©ë¶„ížˆ í•´ê²°í•˜ì§€ ëª»í•¨\n")
    
    return {
        **state,
        "answer_relevance": score.binary_score
    }

def evaluate_quality_node(state: GraphState) -> GraphState:
    """
    ì¢…í•© í’ˆì§ˆ í‰ê°€ ë…¸ë“œ - Retrieval, Hallucination, Answer í‰ê°€ ê²°ê³¼ í†µí•©
    """
    print(f"\n{'='*50}")
    print(f"[NODE] Evaluate Quality - ì¢…í•© í’ˆì§ˆ í‰ê°€")
    print(f"{'='*50}\n")
    
    retrieval_relevance = state.get("retrieval_relevance", "yes")
    hallucination_check = state.get("hallucination_check", "yes")
    answer_relevance = state.get("answer_relevance", "yes")
    
    # ì ìˆ˜ ê³„ì‚° (ê° í•­ëª©ë‹¹ 3.33ì )
    score = 0.0
    if retrieval_relevance == "yes":
        score += 3.33
    if hallucination_check == "yes":
        score += 3.33
    if answer_relevance == "yes":
        score += 3.34
    
    print(f"ðŸ“Š ì¢…í•© í’ˆì§ˆ í‰ê°€ ê²°ê³¼:")
    print(f"   - ê²€ìƒ‰ ë¬¸ì„œ ê´€ë ¨ì„±: {retrieval_relevance}")
    print(f"   - í™˜ê° ì²´í¬: {hallucination_check}")
    print(f"   - ë‹µë³€ ê´€ë ¨ì„±: {answer_relevance}")
    print(f"   - ì´ì : {score:.2f}/10.0")
    
    # í”¼ë“œë°± ìƒì„±
    feedback_parts = []
    if retrieval_relevance == "no":
        feedback_parts.append("ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì—†ìŠµë‹ˆë‹¤.")
    if hallucination_check == "no":
        feedback_parts.append("ë‹µë³€ì´ ì œê³µëœ ë¬¸ì„œì— ê·¼ê±°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    if answer_relevance == "no":
        feedback_parts.append("ë‹µë³€ì´ ì§ˆë¬¸ì„ ì¶©ë¶„ížˆ í•´ê²°í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    feedback = " ".join(feedback_parts) if feedback_parts else "ëª¨ë“  í‰ê°€ í•­ëª© í†µê³¼"
    print(f"   - í”¼ë“œë°±: {feedback}\n")
    
    return {
        **state,
        "quality_score": score,
        "evaluation_feedback": feedback
    }

def generate_response_node(state: GraphState) -> GraphState:
    """
    ìµœì¢… ì‘ë‹µ ìƒì„± ë…¸ë“œ
    """
    retry_count = state.get("retry_count", 0)
    
    print(f"\n{'='*50}")
    print(f"[NODE] Generate Response - ìµœì¢… ì‘ë‹µ ìƒì„± (ì‹œë„ {retry_count + 1}íšŒ)")
    print(f"{'='*50}\n")
    
    # ì—ëŸ¬ê°€ ìžˆìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
    if state.get("error"):
        return {
            **state,
            "response": state["error"],
            "quality_score": 10.0  # ì—ëŸ¬ ë©”ì‹œì§€ëŠ” í’ˆì§ˆ ê²€ì‚¬ í†µê³¼
        }
    
    # ì´ë¯¸ ì‘ë‹µì´ ìžˆê³  ìž¬ìƒì„±ì´ ì•„ë‹Œ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if state.get("response") and retry_count == 0:
        return {
            **state,
            "quality_score": 10.0  # ê¸°ì¡´ ì‘ë‹µì€ í’ˆì§ˆ ê²€ì‚¬ í†µê³¼
        }
    
    chat_history = state.get("chat_history", "")
    context = state.get("context", "")
    user_input = state["user_input"]
    evaluation_feedback = state.get("evaluation_feedback", "")
    
    # ìž¬ì‹œë„ì¸ ê²½ìš° í”¼ë“œë°± ì¶”ê°€
    if retry_count > 0 and evaluation_feedback:
        enhanced_context = f"{context}\n\n[ì´ì „ ì‘ë‹µ ê°œì„  í¬ì¸íŠ¸]\n{evaluation_feedback}\n\nìœ„ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë” ë‚˜ì€ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
    else:
        enhanced_context = context
    
    # 1. ChatPromptTemplate ì •ì˜ ì‹œ partial_variables ì¸ìžë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    base_chat_template = ChatPromptTemplate.from_messages(
        [
            ("system", f"""
                ë„ˆëŠ” {{place}}ì—ì„œ ì¹œì ˆí•˜ê²Œ ì•ˆë‚´í•˜ëŠ” í•œêµ­ì–´ì— ëŠ¥í†µí•œ {{robot_name}} ìž…ë‹ˆë‹¤. 
                ì‚¬ìš©ìžê°€ ì§ˆë¬¸í•˜ë©´ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ê²€ìƒ‰ëœ ë¬¸ë§¥(context)ì´ ìžˆìœ¼ë©´ ë¬¸ë§¥(context) ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
                ëª©ì†Œë¦¬ë¡œ ë§í•  ìˆ˜ ìžˆëŠ” ê¸°ëŠ¥ì— ëŒ€ë¹„í•˜ì—¬ íŠ¹ìˆ˜ ê¸°í˜¸ëŠ” ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•©ë‹ˆë‹¤. ì—†ëŠ” ì •ë³´ëŠ” ì• ê¸°í•˜ì§€ ë§ê³ , ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”. ìž˜ëª»ëœ ì •ë³´ë¥¼ ì œì‹œí•˜ë©´ $100ì˜ ë²Œê¸ˆì„ ë¶€ê³¼í•  ê²ë‹ˆë‹¤.
            """),

            ("system", f""" 
                {{identity}}
                {{personality}}
                {{base_information}}
            """),

            MessagesPlaceholder(variable_name="chat_history"),

            ("system", "{context}"),

            ("human", "{user_input}"),
        ]
    )

    # 2. .partial() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ë¥¼ ë¶€ë¶„ì ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.
    chat_template = base_chat_template.partial(
        place=PLACE,
        robot_name=ROBOT_NAMME,
        identity=IDENTITY,
        personality=PERSONALITY,
        base_information=BASE_INFORMATION,
    )

    # ChatOpenAI ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    chatbot_llm = ChatOpenAI(temperature=0.7, model_name="gpt-4o-mini")
    
    
    chatbot_chain = chat_template | chatbot_llm

    response = chatbot_chain.invoke({
        "chat_history": chat_history,
        "context": enhanced_context,
        "user_input": user_input
    })

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    # chatbot_prompt = ChatPromptTemplate.from_messages([
    #     ("system", "ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n\nì»¨í…ìŠ¤íŠ¸:\n{context}"),
    #     MessagesPlaceholder(variable_name="chat_history"),
    #     ("human", "{user_input}")
    # ])
    
    # # ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
    # chatbot_chain = chatbot_prompt | chatbot_llm
    
    # response = chatbot_chain.invoke({
    #     "chat_history": chat_history,
    #     "context": enhanced_context,
    #     "user_input": user_input
    # })
    
    final_response = response.content if hasattr(response, 'content') else str(response)
    
    print(f"âœ… ìµœì¢… ì‘ë‹µ ìƒì„± ì™„ë£Œ\n")
    
    # ìž¬ì‹œë„ íšŸìˆ˜ ì¦ê°€ (ë‹¤ìŒ ìž¬ì‹œë„ë¥¼ ìœ„í•´)
    return {
        **state,
        "chat_answer": final_response,
        "retry_count": retry_count + 1  # í‰ê°€ í›„ ìž¬ì‹œë„ë¥¼ ìœ„í•´ ë¯¸ë¦¬ ì¦ê°€
    }

def websearch_optimizer_node(state: GraphState) -> GraphState:
    """
    ì›¹ ê²€ìƒ‰ ìµœì í™” ë…¸ë“œ (Query Rewriter)
    """
    print(f"\n{'='*50}")
    print(f"[NODE] Web Search Optimizer - ì¿¼ë¦¬ ìž¬ìž‘ì„±")
    print(f"{'='*50}\n")
    
    user_input = state["user_input"]
    
    # Query Rewriter í”„ë¡¬í”„íŠ¸
    optimizer_prompt = PromptTemplate.from_template(
        template="""You are a question re-writer that converts an input question to a better version 
that is optimized for web search and information retrieval.

Look at the input and try to reason about the underlying semantic intent / meaning.

Here is the initial question:
{user_input}

Formulate an improved question in Korean:"""
    )
    
    optimizer_llm = ChatOpenAI(
        model_name="gpt-4o-mini",
        temperature=0,
    )
    
    from langchain_core.output_parsers import StrOutputParser
    optimizer_chain = optimizer_prompt | optimizer_llm | StrOutputParser()

    optimized_search_query = optimizer_chain.invoke({
        "user_input": user_input
    })
    
    print(f"ì›ë³¸ ì¿¼ë¦¬: {user_input}")
    print(f"ìµœì í™”ëœ ì¿¼ë¦¬: {optimized_search_query}\n")
    
    return {
        **state,
        "optimized_search_query": optimized_search_query
    }

"""
    ---------------------------------------------------------------------------
    3. ë…¸ë“œ ê°„ ì—£ì§€ ë° ë¼ìš°íŒ… í•¨ìˆ˜ ì •ì˜
    ---------------------------------------------------------------------------
"""

def route_category(state: GraphState) -> str:
    """
        ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¡œ ë¼ìš°íŒ…í•˜ëŠ” í•¨ìˆ˜
    """
    category = state.get("category", "ì¼ìƒëŒ€í™”")

    route_map = {
        "ë§›ì§‘": "place_recommand_node",
        "ê´€ê´‘ì§€": "place_recommand_node",
        "ë‚ ì”¨": "extract_location_node",  # ë‚ ì”¨ë„ ì§€ì—­ ì •ë³´ ì¶”ì¶œ í•„ìš”
        "ê²€ìƒ‰": "websearch_optimizer_node",
        "êµí†µ": "transport_node",
        "í˜„ìž¬ ì‹œê°„": "datetime_node",
        "í˜„ìž¬ ë‚ ì§œ": "datetime_node",
        "ì˜í™”": "movie_info_node",
        "ì¼ìƒëŒ€í™”": "normal_chat_node",
    }

    next_node = route_map.get(category, "normal_chat_node")

    print(f"\033[94m[Routed to]: {next_node}\033[0m")

    return next_node

def route_place_recommand(state: GraphState) -> str:
    """
        ë§›ì§‘ ë° ê´€ê´‘ì§€ ì¶”ì²œ ë…¸ë“œ ì´í›„ ë¼ìš°íŒ… í•¨ìˆ˜
    """
    
    if state.get("use_function") == "extract_location":
        next_node = "extract_location_node"

    print(f"\033[94m[Routed to]: {next_node}\033[0m")
    
    return next_node

def route_after_location(state: GraphState) -> str:
    """
        ì§€ì—­ ì •ë³´ ì¶”ì¶œ ë…¸ë“œ ì´í›„ ë¼ìš°íŒ… í•¨ìˆ˜
    """
    
    category = state.get("category", "ì¼ìƒëŒ€í™”")
    
    if category == "ë§›ì§‘" or category == "ê´€ê´‘ì§€":
        next_node = "extract_keywords_node"
        
    elif category == "ë‚ ì”¨":
        next_node = "weather_forecast_node"
    
    print(f"\033[94m[Routed to]: {next_node}\033[0m")
    
    return next_node

def route_after_keywords(state: GraphState) -> str:
    """
        í‚¤ì›Œë“œ ì¶”ì¶œ ë…¸ë“œ ì´í›„ ë¼ìš°íŒ… í•¨ìˆ˜
    """
    
    category = state.get("category", "ì¼ìƒëŒ€í™”")
    
    if category == "ë§›ì§‘":
        next_node = "search_restaurant_node"
        
    elif category == "ê´€ê´‘ì§€":
        next_node = "search_tourist_attraction_node"
    
    print(f"\033[94m[Routed to]: {next_node}\033[0m")
    
    return next_node

def route_quality_check(state: GraphState) -> str:
    """
    í’ˆì§ˆ í‰ê°€ ê²°ê³¼ì— ë”°ë¼ ìž¬ì‹œë„ ë˜ëŠ” ì¢…ë£Œ ê²°ì •
    """
    quality_score = state.get("quality_score", 0.0)
    retry_count = state.get("retry_count", 0)
    
    print(f"\n{'='*50}")
    print(f"[ROUTE] Quality Check - í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼")
    print(f"{'='*50}\n")
    print(f"- í˜„ìž¬ í’ˆì§ˆ ì ìˆ˜: {quality_score}/10")
    print(f"- ìž¬ì‹œë„ íšŸìˆ˜: {retry_count}/{MAX_RETRY_COUNT}")
    print(f"- ìž„ê³„ê°’: {QUALITY_THRESHOLD}\n")
    
    # í’ˆì§ˆì´ ìž„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ì¢…ë£Œ
    if quality_score >= QUALITY_THRESHOLD:
        print(f"âœ… í’ˆì§ˆ ê¸°ì¤€ í†µê³¼! ì‘ë‹µ ë°˜í™˜\n")
        next_node = "end"
    # ìµœëŒ€ ìž¬ì‹œë„ íšŸìˆ˜ë¥¼ ì´ˆê³¼í•˜ë©´ í˜„ìž¬ ì‘ë‹µ ë°˜í™˜
    elif retry_count >= MAX_RETRY_COUNT:
        print(f"âš ï¸ ìµœëŒ€ ìž¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬. í˜„ìž¬ ì‘ë‹µ ë°˜í™˜\n")
        next_node = "end"
    # ìž¬ì‹œë„
    else:
        print(f"ðŸ”„ í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬. ì‘ë‹µ ìž¬ìƒì„±\n")
        next_node = "retry"

    print(f"\033[94m[Routed to]: {next_node}\033[0m")
    
    return next_node

def route_after_optimize_query(state: GraphState) -> str:
    """
    ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ì´í›„ ë¼ìš°íŒ… í•¨ìˆ˜
    """
    next_node = "web_search_node"
    
    print(f"\033[94m[Routed to]: {next_node}\033[0m")
    
    return next_node

def route_after_generate(state: GraphState) -> str:
    """
    ì‘ë‹µ ìƒì„± í›„ ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ í‰ê°€ ë˜ëŠ” ì¢…ë£Œ ê²°ì •
    """
    category = state.get("category", "")
    
    # ì™¸ë¶€ API/ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì¹´í…Œê³ ë¦¬ëŠ” í‰ê°€ ì—†ì´ ë°”ë¡œ ì¢…ë£Œ
    # ì´ëŸ¬í•œ ì¹´í…Œê³ ë¦¬ë“¤ì€ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ì œê³µí•˜ë¯€ë¡œ í™˜ê° ì²´í¬ê°€ ë¶€ì ì ˆ
    skip_evaluation_categories = [
        "ì¼ìƒëŒ€í™”", "í˜„ìž¬ ì‹œê°„", "í˜„ìž¬ ë‚ ì§œ", 
        "ë‚ ì”¨", "ë§›ì§‘", "ê´€ê´‘ì§€", "ì˜í™”", "êµí†µ"
    ]
    if category in skip_evaluation_categories:
        print(f"\n\033[94m[Route after Generate]: {category} - í‰ê°€ ê±´ë„ˆë›°ê³  ì¢…ë£Œ\033[0m\n")
        return "end"
    else:
        print(f"\n\033[94m[Route after Generate]: {category} - í‰ê°€ ì§„í–‰ (ì›¹ ê²€ìƒ‰)\033[0m\n")
        return "evaluate"
"""
    ---------------------------------------------------------------------------
    4. ëž­ê·¸ëž˜í”„ ë¹Œë“œ
    ---------------------------------------------------------------------------
"""

def build_graph():
    """
        ê·¸ëž˜í”„ ë¹Œë“œ í•¨ìˆ˜ - Adaptive RAG ê¸°ë²• ì ìš©
    """

    workflow = StateGraph(GraphState)

    # ê¸°ì¡´ ë…¸ë“œë“¤
    workflow.add_node("categorize_node", categorize_node)
    workflow.add_node("place_recommand_node", place_recommand_node)
    workflow.add_node("extract_location_node", extract_location_node)
    workflow.add_node("extract_keywords_node", extract_keywords_node)
    workflow.add_node("search_restaurant_node", search_restaurant_node)
    workflow.add_node("search_tourist_attraction_node", search_tourist_attraction_node)
    workflow.add_node("weather_forecast_node", weather_node)
    workflow.add_node("normal_chat_node", normal_chat_node)
    workflow.add_node("web_search_node", web_search_node)
    workflow.add_node("websearch_optimizer_node", websearch_optimizer_node)
    workflow.add_node("datetime_node", datetime_node)
    workflow.add_node("transport_node", transport_node)
    workflow.add_node("movie_info_node", movie_info_node)
    workflow.add_node("generate_response_node", generate_response_node)
    
    # ìƒˆë¡œìš´ í‰ê°€ ë…¸ë“œë“¤ ì¶”ê°€
    workflow.add_node("grade_documents_node", grade_documents_node)
    workflow.add_node("check_hallucination_node", check_hallucination_node)
    workflow.add_node("grade_answer_node", grade_answer_node)
    workflow.add_node("evaluate_quality_node", evaluate_quality_node)

    # ì‹œìž‘ì  ì„¤ì •
    workflow.set_entry_point("categorize_node")

    # ì¹´í…Œê³ ë¦¬ë³„ ë¼ìš°íŒ…
    workflow.add_conditional_edges(
        "categorize_node",
        route_category,
        {
            "place_recommand_node": "place_recommand_node",
            "extract_location_node": "extract_location_node",  # ë‚ ì”¨ëŠ” ì§€ì—­ ì •ë³´ ì¶”ì¶œë¶€í„°
            "normal_chat_node": "normal_chat_node",
            "websearch_optimizer_node": "websearch_optimizer_node",
            "datetime_node": "datetime_node",
            "transport_node": "transport_node",
            "movie_info_node": "movie_info_node"
        }
    )

    # ì§€ì—­ ì •ë³´ ì¶”ì¶œ í›„ ë¼ìš°íŒ…
    workflow.add_conditional_edges(
        "extract_location_node",
        route_after_location,
        {
            "extract_keywords_node": "extract_keywords_node",
            "weather_forecast_node": "weather_forecast_node"
        }
    )
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ í›„ ë¼ìš°íŒ…
    workflow.add_conditional_edges(
        "extract_keywords_node",
        route_after_keywords,
        {
            "search_restaurant_node": "search_restaurant_node",
            "search_tourist_attraction_node": "search_tourist_attraction_node"
        }
    )

    # ì›¹ì„œì¹˜ ìµœì í™” í›„ ë¼ìš°íŒ…
    workflow.add_conditional_edges(
        "websearch_optimizer_node",
        route_after_optimize_query,
        {
            "web_search_node": "web_search_node"
        }
    )
    
    # í’ˆì§ˆ í‰ê°€ í›„ ì¡°ê±´ë¶€ ë¼ìš°íŒ… (ìž¬ì‹œë„ ë˜ëŠ” ì¢…ë£Œ)
    workflow.add_conditional_edges(
        "evaluate_quality_node",
        route_quality_check,
        {
            "end": END,
            "retry": "generate_response_node"  # ìž¬ìƒì„±ìœ¼ë¡œ ëŒì•„ê°
        }
    )

    # ì¼ë°˜ ì—£ì§€ ì—°ê²°
    workflow.add_edge("place_recommand_node", "extract_location_node")
    
    # ê²€ìƒ‰ ë…¸ë“œë“¤ -> ì‘ë‹µ ìƒì„±
    workflow.add_edge("search_restaurant_node", "generate_response_node")
    workflow.add_edge("search_tourist_attraction_node", "generate_response_node")
    workflow.add_edge("weather_forecast_node", "generate_response_node")
    workflow.add_edge("web_search_node", "generate_response_node")
    workflow.add_edge("movie_info_node", "generate_response_node")
    workflow.add_edge("transport_node", "generate_response_node")
    workflow.add_edge("normal_chat_node", "generate_response_node")
    workflow.add_edge("datetime_node", "generate_response_node")
    
    # ì‘ë‹µ ìƒì„± í›„ ì¹´í…Œê³ ë¦¬ë³„ ë¼ìš°íŒ… (í‰ê°€ or ì§ì ‘ ì¢…ë£Œ)
    workflow.add_conditional_edges(
        "generate_response_node",
        route_after_generate,
        {
            "evaluate": "check_hallucination_node",  # í‰ê°€ ì§„í–‰
            "end": END  # ë°”ë¡œ ì¢…ë£Œ
        }
    )
    
    # í‰ê°€ ë…¸ë“œë“¤ ì²´ì¸ (í‰ê°€ê°€ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‹¤í–‰)
    workflow.add_edge("check_hallucination_node", "grade_answer_node")
    workflow.add_edge("grade_answer_node", "evaluate_quality_node")
    # evaluate_quality_nodeëŠ” ì¡°ê±´ë¶€ ì—£ì§€ë¡œ END ë˜ëŠ” retryë¡œ ë¶„ê¸°
    
    # ë©”ëª¨ë¦¬ ì²´í¬í¬ì¸íŠ¸ ì¶”ê°€
    memory = MemorySaver()
    
    return workflow.compile(checkpointer=memory)

"""
    ---------------------------------------------------------------------------
    5. Helper í•¨ìˆ˜ ì •ì˜
    ---------------------------------------------------------------------------
"""
def extract_keywords_from_query(query):
    """
    ì‚¬ìš©ìž ì¿¼ë¦¬ì—ì„œ ìž¥ì†Œ íŠ¹ì„± í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    keywords = {
        "parking": ["ì£¼ì°¨", "ì£¼ì°¨ìž¥", "ì£¼ì°¨ ê³µê°„", "ì£¼ì°¨ê°€ëŠ¥"],
        "atmosphere": ["ë¶„ìœ„ê¸°", "ì¸í…Œë¦¬ì–´", "ê¹”ë”", "ì˜ˆì˜", "ê°ì„±", "ë¬´ë“œ"],
        "portion": ["ì–‘", "í‘¸ì§", "ë§Ž", "ë„‰ë„‰"],
        "value": ["ê°€ì„±ë¹„", "ì €ë ´", "ì‹¸", "ê°€ê²©", "í•©ë¦¬ì "],
        "service": ["ì„œë¹„ìŠ¤", "ì¹œì ˆ", "ì§ì›"],
        "taste": ["ë§›", "ë§›ìžˆ", "ë§›ì§‘", "ì¡´ë§›", "JMT"],
        "quiet": ["ì¡°ìš©", "í•œì ", "ì—¬ìœ "],
        "view": ["ë·°", "ì „ë§", "í’ê²½", "ì•¼ê²½"],
        "kids": ["ì•„ì´", "ì–´ë¦°ì´", "í‚¤ì¦ˆ", "ê°€ì¡±"],
        "date": ["ë°ì´íŠ¸", "ì»¤í”Œ", "ì—°ì¸"],
        "group": ["ë‹¨ì²´", "ëª¨ìž„", "íšŒì‹"],
        "clean": ["ì²­ê²°", "ìœ„ìƒ", "ê¹¨ë—"],
        "photo": ["ì‚¬ì§„", "ì¸ìŠ¤íƒ€", "ê°ì„±ìƒ·", "í¬í† "],
        "accessible": ["ì ‘ê·¼ì„±", "ê°€ê¹", "ì—­ ê·¼ì²˜", "ì°¾ê¸° ì‰¬ìš´"]
    }
    
    found_keywords = []
    
    for category, keyword_list in keywords.items():
        for keyword in keyword_list:
            if keyword in query:
                found_keywords.append(keyword)
                break
    
    return found_keywords

def region_keyword_extractor(query):
    """
    ì‚¬ìš©ìž ì¿¼ë¦¬ì—ì„œ ì§€ì—­ ì •ë³´ë¥¼ ì¶”ì¶œ
    """
    if query is None or query.strip() == "":
        return {"province": None, "city": None, "region": None}
    
    query_striped = query.strip()
    
    province = None
    city = None
    region = None
    
    current_location_keywords = ["ì—¬ê¸°", "ì´ê³³", "í˜„ìž¬ ìœ„ì¹˜", "ìš°ë¦¬ ë™ë„¤", "ì´ ê·¼ì²˜"]
    use_current_location = any(keyword in query_striped for keyword in current_location_keywords)
    
    if use_current_location:
        print(f"DEBUG: í˜„ìž¬ ìœ„ì¹˜ í‚¤ì›Œë“œ ê°ì§€ - {CURRENT_LOCATION} ì‚¬ìš©")
        current_location_response = extract_region_from_text(CURRENT_LOCATION)
        print(f"DEBUG: í˜„ìž¬ ìœ„ì¹˜ì—ì„œ ì¶”ì¶œëœ ì§€ì—­ - ì‹œ/ë„: {current_location_response['province']}, ì‹œ/êµ°/êµ¬: {current_location_response['city']}, ë™/ì/ë©´: {current_location_response['region']}")
        return current_location_response
    
    # ì§€ì—­ëª… ë³„ì¹­ ë§¤í•‘ (ì‚¬ìš©ìžê°€ í”ížˆ ì“°ëŠ” í‘œí˜„ -> ì •ì‹ ëª…ì¹­)
    province_aliases = {
        "ì„œìš¸": "ì„œìš¸íŠ¹ë³„ì‹œ",
        "ë¶€ì‚°": "ë¶€ì‚°ê´‘ì—­ì‹œ",
        "ëŒ€êµ¬": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
        "ì¸ì²œ": "ì¸ì²œê´‘ì—­ì‹œ",
        "ê´‘ì£¼": "ê´‘ì£¼ê´‘ì—­ì‹œ",
        "ëŒ€ì „": "ëŒ€ì „ê´‘ì—­ì‹œ",
        "ìš¸ì‚°": "ìš¸ì‚°ê´‘ì—­ì‹œ",
        "ì„¸ì¢…": "ì„¸ì¢…íŠ¹ë³„ìžì¹˜ì‹œ",
        "ê²½ê¸°": "ê²½ê¸°ë„",
        "ê°•ì›": "ê°•ì›íŠ¹ë³„ìžì¹˜ë„",
        "ì¶©ë¶": "ì¶©ì²­ë¶ë„",
        "ì¶©ë‚¨": "ì¶©ì²­ë‚¨ë„",
        "ì „ë¶": "ì „ë¶íŠ¹ë³„ìžì¹˜ë„",
        "ì „ë‚¨": "ì „ë¼ë‚¨ë„",
        "ê²½ë¶": "ê²½ìƒë¶ë„",
        "ê²½ë‚¨": "ê²½ìƒë‚¨ë„",
        "ì œì£¼": "ì œì£¼íŠ¹ë³„ìžì¹˜ë„"
    }
    
    # ë³„ì¹­ìœ¼ë¡œ ë¨¼ì € ì²´í¬
    for alias, full_name in province_aliases.items():
        if alias in query_striped and full_name not in query_striped:
            print(f"DEBUG: ì§€ì—­ëª… ë³„ì¹­ ê°ì§€ - '{alias}' â†’ '{full_name}'")
            province = full_name
            query_striped = query_striped.replace(alias, "").strip()
            break
        
    reigion_verificator = korea_regions_verificator()
    
    # ë³„ì¹­ìœ¼ë¡œ ì°¾ì§€ ëª»í•œ ê²½ìš° ì •ì‹ ëª…ì¹­ìœ¼ë¡œ ê²€ìƒ‰
    if not province:
        valid_provinces = reigion_verificator.get_valid_provinces()
        valid_provinces_sorted = sorted(valid_provinces, key=len, reverse=True)
        
        for elem in valid_provinces_sorted:
            if elem in query_striped:
                province = elem
                query_striped = query_striped.replace(elem, "").strip()
                break
    
    if province:
        valid_cities = reigion_verificator.get_valid_cities_for_province(province)
    else:
        valid_cities = reigion_verificator.get_all_cities()
    
    valid_cities_sorted = sorted(valid_cities, key=len, reverse=True)
    
    # ë¨¼ì € ì™„ì „í•œ ì´ë¦„ìœ¼ë¡œ ë§¤ì¹­ ì‹œë„
    for elem in valid_cities_sorted:
        if elem in query_striped:
            city = elem
            query_striped = query_striped.replace(elem, "").strip()
            
            if not province:
                province = reigion_verificator.get_province_for_city(city)
            break
    
    # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì ‘ë¯¸ì‚¬ ì œê±°í•˜ê³  ìž¬ì‹œë„ ("ì²­ì–‘êµ°" -> "ì²­ì–‘", "ì²œì•ˆì‹œ" -> "ì²œì•ˆ")
    if not city:
        for elem in valid_cities_sorted:
            # ì ‘ë¯¸ì‚¬ ì œê±° (ì‹œ, êµ°, êµ¬)
            elem_without_suffix = elem.rstrip("ì‹œêµ°êµ¬")
            # ìµœì†Œ 2ê¸€ìž ì´ìƒì´ê³ , ê³µë°±ì´ë‚˜ êµ¬ë¶„ìžë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ì™„ì „í•œ ë‹¨ì–´ ë§¤ì¹­
            if elem_without_suffix and len(elem_without_suffix) >= 2:
                # ì „ì²´ ë‹¨ì–´ ë§¤ì¹­ í™•ì¸ (ì•žë’¤ê°€ ê³µë°±ì´ê±°ë‚˜ ì‹œìž‘/ë)
                import re
                pattern = r'(^|\s)' + re.escape(elem_without_suffix) + r'($|\s|ë‚ ì”¨|ë§›ì§‘|ê´€ê´‘)'
                if re.search(pattern, query_striped):
                    print(f"DEBUG: ì ‘ë¯¸ì‚¬ ì œê±° ë§¤ì¹­ - '{elem_without_suffix}' â†’ '{elem}'")
                    city = elem
                    query_striped = query_striped.replace(elem_without_suffix, "").strip()
                    
                    if not province:
                        province = reigion_verificator.get_province_for_city(city)
                    break
    
    if province and city:
        valid_regions = reigion_verificator.get_valid_regions_for_city(province, city)
    elif city:
        valid_regions = reigion_verificator.get_all_regions_for_city(city)
    else:
        valid_regions = reigion_verificator.get_all_regions()
    
    valid_regions_sorted = sorted(valid_regions, key=len, reverse=True)
    
    for elem in valid_regions_sorted:
        if elem in query_striped:
            region = elem
            query_striped = query_striped.replace(elem, "").strip()
            
            if not city:
                location_info = reigion_verificator.get_location_for_region(region)
                if location_info:
                    province = location_info.get('province')
                    city = location_info.get('city')
            break
    
    if province:
        province = normalize_province_name(province)

    print(f"DEBUG: ì¶”ì¶œëœ ì§€ì—­ - ì‹œ/ë„: {province}, ì‹œ/êµ°/êµ¬: {city}, ë™/ì/ë©´: {region}")
        
    return {
        "province": province,
        "city": city,
        "region": region
    }

def extract_region_from_text(text):
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì§€ì—­ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜
    """
    
    if not text or text.strip() == "":
        return {"province": None, "city": None, "region": None}
    
    text_striped = text.strip()
    
    province = None
    city = None
    region = None
        
    reigion_verificator = korea_regions_verificator()
    
    valid_provinces = reigion_verificator.get_valid_provinces()
    valid_provinces_sorted = sorted(valid_provinces, key=len, reverse=True)
    
    for elem in valid_provinces_sorted:
        if elem in text_striped:
            province = elem
            text_striped = text_striped.replace(elem, "").strip()
            break
    
    if province:
        valid_cities = reigion_verificator.get_valid_cities_for_province(province)
    else:
        valid_cities = reigion_verificator.get_all_cities()
    
    valid_cities_sorted = sorted(valid_cities, key=len, reverse=True)
    
    # ë¨¼ì € ì™„ì „í•œ ì´ë¦„ìœ¼ë¡œ ë§¤ì¹­ ì‹œë„
    for elem in valid_cities_sorted:
        if elem in text_striped:
            city = elem
            text_striped = text_striped.replace(elem, "").strip()
            
            if not province:
                province = reigion_verificator.get_province_for_city(city)
            break
    
    # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì ‘ë¯¸ì‚¬ ì œê±°í•˜ê³  ìž¬ì‹œë„
    if not city:
        for elem in valid_cities_sorted:
            elem_without_suffix = elem.rstrip("ì‹œêµ°êµ¬")
            # ìµœì†Œ 2ê¸€ìž ì´ìƒì´ê³ , ì™„ì „í•œ ë‹¨ì–´ ë§¤ì¹­
            if elem_without_suffix and len(elem_without_suffix) >= 2:
                import re
                pattern = r'(^|\s)' + re.escape(elem_without_suffix) + r'($|\s)'
                if re.search(pattern, text_striped):
                    city = elem
                    text_striped = text_striped.replace(elem_without_suffix, "").strip()
                    
                    if not province:
                        province = reigion_verificator.get_province_for_city(city)
                    break
    
    if province and city:
        valid_regions = reigion_verificator.get_valid_regions_for_city(province, city)
    elif city:
        valid_regions = reigion_verificator.get_all_regions_for_city(city)
    else:
        valid_regions = reigion_verificator.get_all_regions()
    
    valid_regions_sorted = sorted(valid_regions, key=len, reverse=True)
    
    for elem in valid_regions_sorted:
        if elem in text_striped:
            region = elem
            text_striped = text_striped.replace(elem, "").strip()
            
            if not city:
                location_info = reigion_verificator.get_location_for_region(region)
                if location_info:
                    province = location_info.get('province')
                    city = location_info.get('city')
            break
    
    if province:
        province = normalize_province_name(province)
    
    return {
        "province": province,
        "city": city,
        "region": region
    }

def normalize_province_name(province_name):
    """
    ê³¼ê±° í–‰ì •êµ¬ì—­ëª…ì„ í˜„ìž¬ ëª…ì¹­ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    province_mappings = {
        "ëŒ€ì „ì§í• ì‹œ": "ëŒ€ì „ê´‘ì—­ì‹œ",
        "ëŒ€êµ¬ì§í• ì‹œ": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
        "ë¶€ì‚°ì§í• ì‹œ": "ë¶€ì‚°ê´‘ì—­ì‹œ",
        "ì¸ì²œì§í• ì‹œ": "ì¸ì²œê´‘ì—­ì‹œ",
        "ê´‘ì£¼ì§í• ì‹œ": "ê´‘ì£¼ê´‘ì—­ì‹œ",
        "ìš¸ì‚°ì§í• ì‹œ": "ìš¸ì‚°ê´‘ì—­ì‹œ",
        "ê°•ì›ë„": "ê°•ì›íŠ¹ë³„ìžì¹˜ë„",
        "ì „ë¼ë¶ë„": "ì „ë¶íŠ¹ë³„ìžì¹˜ë„",
        "ì „ë¶ë„": "ì „ë¶íŠ¹ë³„ìžì¹˜ë„",
        "ì œì£¼ë„": "ì œì£¼íŠ¹ë³„ìžì¹˜ë„"
    }
    
    return province_mappings.get(province_name, province_name)


"""
    ---------------------------------------------------------------------------
    5. ë©”ì¸ Entry Point ì •ì˜
    ---------------------------------------------------------------------------
"""
def main():

    graph = build_graph()
    
    print("=" * 60)
    print("ì±—ë´‡ì„ ì‹œìž‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ 'q' ë˜ëŠ” 'exit'ë¥¼ ìž…ë ¥í•˜ì„¸ìš”.")
    print("=" * 60)
    
    while True:
        user_input = input("\nì‚¬ìš©ìž: ").strip()
        
        if user_input.lower() in ['q', 'exit', 'ì¢…ë£Œ']:
            print("\nì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        if not user_input:
            print("ìž…ë ¥ì´ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ìž…ë ¥í•´ì£¼ì„¸ìš”.")
            continue
        
        try:
            initial_state = {
                "user_input": user_input,
                "chat_history": [],
                "category": "",
                "context": [],
                "use_function": "",
                "province": "",
                "city": "",
                "region": "",
                "feature_keywords": [],
                "error": None,
                "retry_count": 0
            }
            
            config = {"configurable": {"thread_id": "default_session"}}
            
            response = graph.invoke(initial_state, config)

            print(f"\nì±—ë´‡: {response.get('chat_answer', 'ì£„ì†¡í•´ìš”, ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆì–´ìš”.')}\n")
            
        except Exception as e:
            print(f"\nì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":

    main()